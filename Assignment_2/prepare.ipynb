{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "42b9b289",
            "metadata": {},
            "source": [
                "# SMS Spam Data Preparation with DVC (Unstratified)\n",
                "\n",
                "This notebook downloads the SMS Spam Collection dataset, splits it into training, validation, and test sets (without stratification), and uses DVC to track the data versions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "103c4b4f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hello World\n"
                    ]
                }
            ],
            "source": [
                "print(\"Hello World\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c9da96a8",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:32.757036Z",
                    "iopub.status.busy": "2026-02-13T14:31:32.755523Z",
                    "iopub.status.idle": "2026-02-13T14:31:39.867600Z",
                    "shell.execute_reply": "2026-02-13T14:31:39.864823Z"
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import zipfile\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "import subprocess"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d908fe1d",
            "metadata": {},
            "source": [
                "## 1. Download and Extract Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "0b11340e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:39.876018Z",
                    "iopub.status.busy": "2026-02-13T14:31:39.874940Z",
                    "iopub.status.idle": "2026-02-13T14:31:43.907593Z",
                    "shell.execute_reply": "2026-02-13T14:31:43.902675Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data already exists.\n"
                    ]
                }
            ],
            "source": [
                "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
                "zip_path = \"smsspamcollection.zip\"\n",
                "data_file = \"SMSSpamCollection\"\n",
                "\n",
                "if not os.path.exists(data_file):\n",
                "    print(f\"Downloading dataset from {url}...\")\n",
                "    response = requests.get(url)\n",
                "    with open(zip_path, 'wb') as f:\n",
                "        f.write(response.content)\n",
                "\n",
                "    print(\"Extracting dataset...\")\n",
                "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
                "        zip_ref.extractall(\".\")\n",
                "    print(\"Data downloaded and extracted.\")\n",
                "else:\n",
                "    print(\"Data already exists.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7ae29c2",
            "metadata": {},
            "source": [
                "## 2. Process and Save Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "6b526a93",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:43.925610Z",
                    "iopub.status.busy": "2026-02-13T14:31:43.924594Z",
                    "iopub.status.idle": "2026-02-13T14:31:44.171982Z",
                    "shell.execute_reply": "2026-02-13T14:31:44.167266Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Raw data saved to raw_data.csv with 5572 records.\n"
                    ]
                }
            ],
            "source": [
                "# Load raw data (tab-separated, no header)\n",
                "df = pd.read_csv(data_file, sep='\\t', names=['label', 'text'])\n",
                "df.to_csv('raw_data.csv', index=False)\n",
                "print(f\"Raw data saved to raw_data.csv with {len(df)} records.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b633d559",
            "metadata": {},
            "source": [
                "## 3. Split Data into Train, Validation, and Test (Seed 42 - Unstratified)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "5667eee5",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:44.198521Z",
                    "iopub.status.busy": "2026-02-13T14:31:44.196254Z",
                    "iopub.status.idle": "2026-02-13T14:31:44.364960Z",
                    "shell.execute_reply": "2026-02-13T14:31:44.360731Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train size: 4457\n",
                        "Validation size: 557\n",
                        "Test size: 558\n"
                    ]
                }
            ],
            "source": [
                "# Split: 80% train, 10% validation, 10% test (Unstratified)\n",
                "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42) # Removed stratify\n",
                "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42) # Removed stratify\n",
                "\n",
                "train_df.to_csv('train.csv', index=False)\n",
                "val_df.to_csv('validation.csv', index=False)\n",
                "test_df.to_csv('test.csv', index=False)\n",
                "\n",
                "print(f\"Train size: {len(train_df)}\")\n",
                "print(f\"Validation size: {len(val_df)}\")\n",
                "print(f\"Test size: {len(test_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a2cce3a8",
            "metadata": {},
            "source": [
                "## 4. Track with DVC (v1.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "df974313",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:44.381421Z",
                    "iopub.status.busy": "2026-02-13T14:31:44.380392Z",
                    "iopub.status.idle": "2026-02-13T14:31:54.067904Z",
                    "shell.execute_reply": "2026-02-13T14:31:54.066719Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Adding files to DVC...\n",
                        "\n",
                        "To track the changes with git, run:\n",
                        "\n",
                        "\tgit add raw_data.csv.dvc validation.csv.dvc train.csv.dvc test.csv.dvc\n",
                        "\n",
                        "To enable auto staging, run:\n",
                        "\n",
                        "\tdvc config core.autostage true\n",
                        "\n",
                        "Committing DVC changes to Git...\n",
                        "\n",
                        "[master c6ae12c] Add unstratified data versions (Seed 42)\n",
                        " 3 files changed, 6 insertions(+), 6 deletions(-)\n",
                        "\n",
                        "fatal: tag 'v1.0' already exists\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "def run_command(cmd):\n",
                "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "    if result.returncode == 0:\n",
                "        print(result.stdout)\n",
                "    else:\n",
                "        print(result.stderr)\n",
                "\n",
                "print(\"Adding files to DVC...\")\n",
                "run_command(\"dvc add raw_data.csv train.csv validation.csv test.csv\")\n",
                "\n",
                "print(\"Committing DVC changes to Git...\")\n",
                "run_command(\"git add raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc .gitignore\")\n",
                "run_command('git commit -m \"Add unstratified data versions (Seed 42)\"')\n",
                "run_command('git tag -a v1.0 -m \"Unstratified version with seed 42\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "new-split-header",
            "metadata": {},
            "source": [
                "## 5. Update Split with a Different Random Seed (Seed 100 - Unstratified)\n",
                "\n",
                "In this section, we'll re-split the data using a different random seed without stratification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "new-split-code",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:54.076234Z",
                    "iopub.status.busy": "2026-02-13T14:31:54.074438Z",
                    "iopub.status.idle": "2026-02-13T14:31:54.171177Z",
                    "shell.execute_reply": "2026-02-13T14:31:54.168615Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Updating splits with random_state=100...\n",
                        "New Train size: 4457\n",
                        "New Validation size: 557\n",
                        "New Test size: 558\n"
                    ]
                }
            ],
            "source": [
                "new_seed = 100\n",
                "print(f\"Updating splits with random_state={new_seed}...\")\n",
                "\n",
                "train_df_new, temp_df_new = train_test_split(df, test_size=0.2, random_state=new_seed) # Removed stratify\n",
                "val_df_new, test_df_new = train_test_split(temp_df_new, test_size=0.5, random_state=new_seed) # Removed stratify\n",
                "\n",
                "train_df_new.to_csv('train.csv', index=False)\n",
                "val_df_new.to_csv('validation.csv', index=False)\n",
                "test_df_new.to_csv('test.csv', index=False)\n",
                "\n",
                "print(f\"New Train size: {len(train_df_new)}\")\n",
                "print(f\"New Validation size: {len(val_df_new)}\")\n",
                "print(f\"New Test size: {len(test_df_new)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "new-track-header",
            "metadata": {},
            "source": [
                "## 6. Track New Version with DVC (v2.0)\n",
                "\n",
                "Now we'll track this new unstratified version of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "new-track-code",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-02-13T14:31:54.181504Z",
                    "iopub.status.busy": "2026-02-13T14:31:54.180183Z",
                    "iopub.status.idle": "2026-02-13T14:32:02.196109Z",
                    "shell.execute_reply": "2026-02-13T14:32:02.190714Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Adding new data versions to DVC...\n",
                        "\n",
                        "To track the changes with git, run:\n",
                        "\n",
                        "\tgit add train.csv.dvc validation.csv.dvc test.csv.dvc\n",
                        "\n",
                        "To enable auto staging, run:\n",
                        "\n",
                        "\tdvc config core.autostage true\n",
                        "\n",
                        "Committing updated DVC pointers to Git...\n",
                        "\n",
                        "[master 78487fa] Update unstratified data splits (Seed 100)\n",
                        " 3 files changed, 6 insertions(+), 6 deletions(-)\n",
                        "\n",
                        "fatal: tag 'v2.0' already exists\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"Adding new data versions to DVC...\")\n",
                "run_command(\"dvc add train.csv validation.csv test.csv\")\n",
                "\n",
                "print(\"Committing updated DVC pointers to Git...\")\n",
                "run_command(\"git add train.csv.dvc validation.csv.dvc test.csv.dvc\")\n",
                "run_command(f'git commit -m \"Update unstratified data splits (Seed {new_seed})\"')\n",
                "run_command('git tag -a v2.0 -m \"Unstratified version with seed 100\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "compare-dist-header",
            "metadata": {},
            "source": [
                "## 8. Compare Distributions (v1.0 vs v2.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "compare-dist-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_distribution(tag_name):\n",
                "    print(f\"\\n--- Checking out {tag_name} ---\")\n",
                "    # Checkout .dvc files from the git tag\n",
                "    run_command(f\"git checkout {tag_name} -- train.csv.dvc validation.csv.dvc test.csv.dvc\")\n",
                "    # DVC checkout to restore data\n",
                "    run_command(\"dvc checkout\")\n",
                "\n",
                "    for filename in ['train.csv', 'validation.csv', 'test.csv']:\n",
                "        if os.path.exists(filename):\n",
                "            df = pd.read_csv(filename)\n",
                "            print(f\"Distribution for {filename} ({tag_name}):\")\n",
                "            print(df['label'].value_counts())\n",
                "            print(\"-\" * 20)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "fe6d85cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Checking out v1.0 ---\n",
                        "\n",
                        "M       test.csv\n",
                        "M       train.csv\n",
                        "M       validation.csv\n",
                        "\n",
                        "Distribution for train.csv (v1.0):\n",
                        "label\n",
                        "ham     3859\n",
                        "spam     598\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n",
                        "Distribution for validation.csv (v1.0):\n",
                        "label\n",
                        "ham     485\n",
                        "spam     72\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n",
                        "Distribution for test.csv (v1.0):\n",
                        "label\n",
                        "ham     481\n",
                        "spam     77\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n"
                    ]
                }
            ],
            "source": [
                "# 1. Checkout v1.0 and print distribution\n",
                "get_distribution(\"v1.0\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "29feaa22",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Checking out v2.0 ---\n",
                        "\n",
                        "M       test.csv\n",
                        "M       train.csv\n",
                        "M       validation.csv\n",
                        "\n",
                        "Distribution for train.csv (v2.0):\n",
                        "label\n",
                        "ham     3857\n",
                        "spam     600\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n",
                        "Distribution for validation.csv (v2.0):\n",
                        "label\n",
                        "ham     490\n",
                        "spam     67\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n",
                        "Distribution for test.csv (v2.0):\n",
                        "label\n",
                        "ham     478\n",
                        "spam     80\n",
                        "Name: count, dtype: int64\n",
                        "--------------------\n"
                    ]
                }
            ],
            "source": [
                "# 2. Checkout v2.0 and print distribution\n",
                "get_distribution(\"v2.0\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5d0c6542",
            "metadata": {},
            "source": [
                "## BONUS: (decouple compute and storage) track the data versions using google drive as storage\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "90ba335f",
            "metadata": {},
            "source": [
                "### NOTE : I have NOT exposed my OAUTH Client ID and Client Secret here BUT I have used for authentication\n",
                "\n",
                "DVC Remote Storage : Google Drive Path : https://drive.google.com/drive/folders/1gMTOXybo0KtEAHUu-uHj9iaQlTC3lPQt?usp=sharing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2335617e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# run_command(\"dvc remote modify myremote gdrive_client_id MY_CLIENT_ID\")\n",
                "# run_command(\"dvc remote modify myremote gdrive_client_secret MY_CLIENT_SECRET\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4ef5319a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Your browser has been opened to visit:\n",
                        "\n",
                        "    https://accounts.google.com/o/oauth2/auth?client_id=142561804177-am7q7haaassvih0pu36d8ovqbl0ostgi.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n",
                        "\n",
                        "Authentication successful.\n",
                        "4 files pushed\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "run_command(\"dvc push\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "push-all-header",
            "metadata": {},
            "source": [
                "## 10. Push All Versions to Remote\n",
                "\n",
                "We ensure all tagged versions (v1.0 and v2.0) are pushed to Google Drive using `dvc push --all-tags`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "push-all-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pushing all tags to remote...\n",
                        "Everything is up to date.\n",
                        "\n",
                        "Push complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Pushing all tags to remote...\")\n",
                "run_command(\"dvc push --all-tags\")\n",
                "print(\"Push complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "verify-remote-header",
            "metadata": {},
            "source": [
                "## 11. Verify Remote Retrieval\n",
                "\n",
                "We will simulate retrieving data from the remote by deleting local data and pulling specific versions from Google Drive.\n",
                "**Note**: We use `git checkout <tag> -- <file>.dvc` to update the DVC pointer files without changing the notebook itself."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "verify-remote-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Verifying Remote Pull for v1.0 ---\n",
                        "\n",
                        "A       raw_data.csv\n",
                        "A       test.csv\n",
                        "A       train.csv\n",
                        "A       validation.csv\n",
                        "4 files added\n",
                        "\n",
                        "SUCCESS: Data for v1.0 pulled from remote.\n",
                        "Train rows: 4457\n",
                        "\n",
                        "--- Verifying Remote Pull for v2.0 ---\n",
                        "\n",
                        "A       raw_data.csv\n",
                        "A       test.csv\n",
                        "A       train.csv\n",
                        "A       validation.csv\n",
                        "4 files added\n",
                        "\n",
                        "SUCCESS: Data for v2.0 pulled from remote.\n",
                        "Train rows: 4457\n",
                        "\n",
                        "--- Restoring HEAD ---\n",
                        "\n",
                        "Everything is up to date.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "def verify_version(tag):\n",
                "    print(f\"\\n--- Verifying Remote Pull for {tag} ---\")\n",
                "    \n",
                "    # 1. Update DVC files to match the tag\n",
                "    dvc_files = \"raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc\"\n",
                "    run_command(f\"git checkout {tag} -- {dvc_files}\")\n",
                "    \n",
                "    # 2. Delete local data to force pull\n",
                "    for f in ['raw_data.csv', 'train.csv', 'validation.csv', 'test.csv']:\n",
                "        if os.path.exists(f):\n",
                "            os.remove(f)\n",
                "    \n",
                "    # 3. Pull from remote\n",
                "    # This will fail if data is not on the remote\n",
                "    run_command(\"dvc pull\")\n",
                "    \n",
                "    # 4. Verify existence\n",
                "    if os.path.exists(\"train.csv\"):\n",
                "        print(f\"SUCCESS: Data for {tag} pulled from remote.\")\n",
                "        # Optional: Print row count to match version\n",
                "        import pandas as pd\n",
                "        print(f\"Train rows: {len(pd.read_csv('train.csv'))}\")\n",
                "    else:\n",
                "        print(f\"FAILURE: Data for {tag} NOT found after pull.\")\n",
                "\n",
                "# Verify v1.0\n",
                "verify_version(\"v1.0\")\n",
                "\n",
                "# Verify v2.0\n",
                "verify_version(\"v2.0\")\n",
                "\n",
                "# Restore DVC files to HEAD (Current state)\n",
                "print(\"\\n--- Restoring HEAD ---\")\n",
                "run_command(\"git checkout HEAD -- raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc\")\n",
                "run_command(\"dvc pull\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "7576a64f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== Distribution Analysis for v1.0 ===\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "A       test.csv\n",
                        "A       train.csv\n",
                        "A       validation.csv\n",
                        "3 files added\n",
                        "\n",
                        "\n",
                        "--- train.csv (v1.0) ---\n",
                        "label\n",
                        "ham     3859\n",
                        "spam     598\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 4457\n",
                        "\n",
                        "--- validation.csv (v1.0) ---\n",
                        "label\n",
                        "ham     485\n",
                        "spam     72\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 557\n",
                        "\n",
                        "--- test.csv (v1.0) ---\n",
                        "label\n",
                        "ham     481\n",
                        "spam     77\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 558\n",
                        "\n",
                        "=== Distribution Analysis for v2.0 ===\n",
                        "\n",
                        "A       test.csv\n",
                        "A       train.csv\n",
                        "A       validation.csv\n",
                        "3 files added\n",
                        "\n",
                        "\n",
                        "--- train.csv (v2.0) ---\n",
                        "label\n",
                        "ham     3857\n",
                        "spam     600\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 4457\n",
                        "\n",
                        "--- validation.csv (v2.0) ---\n",
                        "label\n",
                        "ham     490\n",
                        "spam     67\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 557\n",
                        "\n",
                        "--- test.csv (v2.0) ---\n",
                        "label\n",
                        "ham     478\n",
                        "spam     80\n",
                        "Name: count, dtype: int64\n",
                        "Total rows: 558\n",
                        "\n",
                        "=== Restoring HEAD ===\n",
                        "\n",
                        "Everything is up to date.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "def analyze_distribution(tag):\n",
                "    print(f\"\\n=== Distribution Analysis for {tag} ===\")\n",
                "    \n",
                "    # 1. Checkout DVC files\n",
                "    dvc_files = \"raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc\"\n",
                "    run_command(f\"git checkout {tag} -- {dvc_files}\")\n",
                "    \n",
                "    # 2. Force pull data\n",
                "    for f in ['train.csv', 'validation.csv', 'test.csv']:\n",
                "        if os.path.exists(f):\n",
                "            os.remove(f)\n",
                "    run_command(\"dvc pull\")\n",
                "    \n",
                "    # 3. Analyze\n",
                "    for filename in ['train.csv', 'validation.csv', 'test.csv']:\n",
                "        if os.path.exists(filename):\n",
                "            df = pd.read_csv(filename)\n",
                "            print(f\"\\n--- {filename} ({tag}) ---\")\n",
                "            print(df['label'].value_counts())\n",
                "            print(f\"Total rows: {len(df)}\")\n",
                "        else:\n",
                "            print(f\"Warning: {filename} not found for {tag}\")\n",
                "\n",
                "# Analyze v1.0\n",
                "analyze_distribution(\"v1.0\")\n",
                "\n",
                "# Analyze v2.0\n",
                "analyze_distribution(\"v2.0\")\n",
                "\n",
                "# Restore HEAD\n",
                "print(\"\\n=== Restoring HEAD ===\")\n",
                "run_command(\"git checkout HEAD -- raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc\")\n",
                "run_command(\"dvc pull\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
